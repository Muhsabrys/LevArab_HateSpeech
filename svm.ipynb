{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import pandas as pd\n",
    "from sklearn import svm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 1: read in input args**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parser = argparse.ArgumentParser()\n",
    "# parser.add_argument('--train_path', type=str, required=True)    # path to training data\n",
    "# parser.add_argument('--test_path', type=str, required=True)     # path to test data \n",
    "# parser.add_argument('--output_path', type=str, required=True)   # path to output file (metric results)\n",
    "# args = parser.parse_args()\n",
    "\n",
    "TRAIN_PATH = \"/Users/lilykawaoto/Documents/GitHub/LING-L715/lhsab_train.tsv\"\n",
    "TEST_PATH = \"/Users/lilykawaoto/Documents/GitHub/LING-L715/lhsab_test.tsv\"\n",
    "OUTPUT_PATH = \"/Users/lilykawaoto/Documents/GitHub/LING-L715/lhsab_svm_output.txt\"\n",
    "\n",
    "# with open(args.train_path, 'r') as train_f:\n",
    "with open(TRAIN_PATH, 'r') as train_f:\n",
    "    col_names = [\"text\", \"label\"]\n",
    "    train_df = pd.read_csv(train_f, delimiter=\"\\t\", names=col_names)\n",
    "    # df.head()\n",
    "    x_train = [row[0] for row in train_df.itertuples(index=False)]\n",
    "    y_train = [row[1] for row in train_df.itertuples(index=False)]\n",
    "\n",
    "# with open(args.test_path, 'r') as test_f:\n",
    "with open(TEST_PATH, 'r') as test_f:\n",
    "    col_names = [\"text\", \"label\"]\n",
    "    test_df = pd.read_csv(train_f, delimiter=\"\\t\", names=col_names)\n",
    "    x_test = [row[0] for row in test_df.itertuples(index=False)]\n",
    "    y_test = [row[1] for row in test_df.itertuples(index=False)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 2:   create unigrams, unigrams+bigrams, unigrams+bigrams+trigrams\n",
    "            create term-frequency ratings with thresholds of 2 & 3   // term-freq: the relative freq of a term t within a document d**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_ngram(n, threshold, txt_list):\n",
    "    ngrams_dict = {}\n",
    "    # ngrams_list = []\n",
    "    for txt in txt_list:\n",
    "        if n==1:        # make unigrams\n",
    "            words = txt.split(\" \")\n",
    "            for word in words:\n",
    "                # ngrams_list.append(word)\n",
    "                if ngrams_dict[word] == 0:\n",
    "                    ngrams_dict[word] = 1\n",
    "                else:\n",
    "                    ngrams_dict[word] += 1\n",
    "\n",
    "        elif n==2:      # make bigrams\n",
    "            words = txt.split(\" \")\n",
    "            for i,word in enumerate(words):\n",
    "                if i==0:\n",
    "                    continue\n",
    "                else:\n",
    "                    # ngrams_list.append((txt[i-1], word))\n",
    "                    if ngrams_dict[(words[i-1], word)] == 0:\n",
    "                        ngrams_dict[(words[i-1], word)] = 1\n",
    "                    else:\n",
    "                        ngrams_dict[(words[i-1], word)] += 1\n",
    "\n",
    "        elif n==3:      # make trigrams\n",
    "            words = txt.split(\" \")\n",
    "            if len(words) < 3:\n",
    "                continue\n",
    "            for i,word in enumerate(words):\n",
    "                if i<2:\n",
    "                    continue\n",
    "                else: \n",
    "                    # ngrams_list.append((txt[i-2], txt[i-1], word))\n",
    "                    if ngrams_dict[(words[i-2], words[i-1], word)] == 0:\n",
    "                        ngrams_dict[(words[i-2], words[i-1], word)] = 1\n",
    "                    else: \n",
    "                        ngrams_dict[(words[i-2], words[i-1], word)] += 1\n",
    "\n",
    "    assert(threshold==2 or threshold==3)\n",
    "    if threshold==2:\n",
    "        ngrams_dict = {key:val for key, val in ngrams_dict.items() if val>2}\n",
    "\n",
    "    elif threshold==3:\n",
    "        ngrams_dict = {key:val for key, val in ngrams_dict.items() if val>3}\n",
    "\n",
    "    return ngrams_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# threshold == 2\n",
    "train_unigrams_2 = list(make_ngram(1, 2, x_train).keys())\n",
    "train_bigrams_2 = list(make_ngram(2, 2, x_train).keys())\n",
    "train_trigrams_2 = list(make_ngram(3, 2, x_train).keys())\n",
    "\n",
    "test_unigrams_2 = list(make_ngram(1, 2, x_train).keys())\n",
    "test_bigrams_2 = list(make_ngram(2, 2, x_train).keys())\n",
    "test_trigrams_2 = list(make_ngram(3, 2, x_train).keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# threshold == 3\n",
    "train_unigrams_3 = list(make_ngram(1, 3, x_train).keys())\n",
    "train_bigrams_3 = list(make_ngram(2, 3, x_train).keys())\n",
    "train_trigrams_3 = list(make_ngram(3, 3, x_train).keys())\n",
    "\n",
    "test_unigrams_3 = list(make_ngram(1, 3, x_train).keys())\n",
    "test_bigrams_3 = list(make_ngram(2, 3, x_train).keys())\n",
    "test_trigrams_3 = list(make_ngram(3, 3, x_train).keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 3: train & predict**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# unigrams, threshold 2\n",
    "clf = svm.SVC(kernel='linear')\n",
    "clf.fit(train_unigrams_2, y_train)\n",
    "y_pred = clf.predict(test_unigrams_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# unigrams + bigrams, threshold 2\n",
    "clf = svm.SVC(kernel='linear')\n",
    "clf.fit(train_unigrams_2+train_bigrams_2, test_unigrams_2+test_bigrams_2)\n",
    "y_pred = clf.predict(test_unigrams_2+test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
